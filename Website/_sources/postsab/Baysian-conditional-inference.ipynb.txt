{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9572985c-0bbe-4df1-bf8c-24bd78b39d01",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Follow A Bayesian, Or People Die!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4838819-43e5-481a-9631-5b432c96361f",
   "metadata": {},
   "source": [
    "ğ˜›ğ˜©ğ˜ªğ˜´ ğ˜ªğ˜´ ğ˜¢ ğ˜¸ğ˜³ğ˜ªğ˜µğ˜¦-ğ˜¶ğ˜± ğ˜°ğ˜§ ğ˜´ğ˜°ğ˜®ğ˜¦ ğ˜µğ˜©ğ˜°ğ˜¶ğ˜¨ğ˜©ğ˜µğ˜´ ğ˜ ğ˜©ğ˜¢ğ˜¥ ğ˜¢ğ˜µ ğ˜µğ˜©ğ˜¦ ğ˜£ğ˜¦ğ˜¨ğ˜ªğ˜¯ğ˜¯ğ˜ªğ˜¯ğ˜¨ ğ˜°ğ˜§ ğ˜µğ˜©ğ˜¦ ğ˜±ğ˜¢ğ˜¯ğ˜¥ğ˜¦ğ˜®ğ˜ªğ˜¤, ğ˜­ğ˜°ğ˜°ğ˜¬ğ˜ªğ˜¯ğ˜¨ ğ˜£ğ˜¢ğ˜¤ğ˜¬ ğ˜µğ˜° ğ˜´ğ˜°ğ˜®ğ˜¦ ğ˜¢ğ˜´ğ˜±ğ˜¦ğ˜¤ğ˜µğ˜´ ğ˜°ğ˜§ ğ˜µğ˜©ğ˜¦ ğ˜ğ˜³ğ˜¦ğ˜²ğ˜¶ğ˜¦ğ˜¯ğ˜µğ˜ªğ˜´ğ˜µ ğ˜·ğ˜´. ğ˜‰ğ˜¢ğ˜ºğ˜¦ğ˜´ğ˜ªğ˜¢ğ˜¯ ğ˜¥ğ˜¦ğ˜£ğ˜¢ğ˜µğ˜¦. ğ˜'ğ˜® ğ˜¯ğ˜°ğ˜µ ğ˜ªğ˜¯ ğ˜µğ˜©ğ˜¦ ğ˜±ğ˜°ğ˜´ğ˜ªğ˜µğ˜ªğ˜°ğ˜¯ ğ˜µğ˜° ğ˜¢ğ˜¥ğ˜¥ ğ˜¢ğ˜¯ğ˜ºğ˜µğ˜©ğ˜ªğ˜¯ğ˜¨ ğ˜¯ğ˜¦ğ˜¸ ğ˜µğ˜° ğ˜µğ˜©ğ˜¦ ğ˜µğ˜°ğ˜±ğ˜ªğ˜¤, ğ˜£ğ˜¶ğ˜µ ğ˜ ğ˜¸ğ˜ªğ˜­ğ˜­ ğ˜¶ğ˜´ğ˜¦ ğ˜µğ˜©ğ˜¦ ğ˜¯ğ˜¦ğ˜¸ğ˜´ ğ˜°ğ˜§ ğ˜µğ˜©ğ˜¢ğ˜µ ğ˜µğ˜ªğ˜®ğ˜¦ ğ˜µğ˜° ğ˜¨ğ˜ªğ˜·ğ˜¦ ğ˜¢ğ˜¯ ğ˜¦ğ˜¹ğ˜¢ğ˜®ğ˜±ğ˜­ğ˜¦ ğ˜¸ğ˜©ğ˜¦ğ˜³ğ˜¦ ğ˜ğ˜³ğ˜¦ğ˜²ğ˜¶ğ˜¦ğ˜¯ğ˜µğ˜ªğ˜´ğ˜µ ğ˜¢ğ˜¯ğ˜¥ ğ˜‰ğ˜¢ğ˜ºğ˜¦ğ˜´ğ˜ªğ˜¢ğ˜¯ ğ˜¨ğ˜ªğ˜·ğ˜¦ ğ˜¥ğ˜ªğ˜§ğ˜§ğ˜¦ğ˜³ğ˜¦ğ˜¯ğ˜µ ğ˜¢ğ˜¯ğ˜´ğ˜¸ğ˜¦ğ˜³ğ˜´. ğ˜ğ˜µ ğ˜ªğ˜´ ğ˜¢ ğ˜¤ğ˜­ğ˜¢ğ˜´ğ˜´ğ˜ªğ˜¤ ğ˜¤ğ˜°ğ˜¯ğ˜¥ğ˜ªğ˜µğ˜ªğ˜°ğ˜¯ğ˜¢ğ˜­ ğ˜´ğ˜µğ˜¢ğ˜µğ˜ªğ˜´ğ˜µğ˜ªğ˜¤ğ˜¢ğ˜­ ğ˜ªğ˜¯ğ˜§ğ˜¦ğ˜³ğ˜¦ğ˜¯ğ˜¤ğ˜¦, ğ˜¦ğ˜¢ğ˜´ğ˜º ğ˜ªğ˜§ ğ˜ºğ˜°ğ˜¶ ğ˜©ğ˜¢ğ˜·ğ˜¦ ğ˜¢ ğ˜¥ğ˜¦ğ˜¦ğ˜± ğ˜¶ğ˜¯ğ˜¥ğ˜¦ğ˜³ğ˜´ğ˜µğ˜¢ğ˜¯ğ˜¥ğ˜ªğ˜¯ğ˜¨ ğ˜°ğ˜§ ğ˜µğ˜©ğ˜¦ ğ˜¥ğ˜ªğ˜§ğ˜§ğ˜¦ğ˜³ğ˜¦ğ˜¯ğ˜¤ğ˜¦ğ˜´ ğ˜£ğ˜¦ğ˜µğ˜¸ğ˜¦ğ˜¦ğ˜¯ ğ˜ğ˜³ğ˜¦ğ˜²ğ˜¶ğ˜¦ğ˜¯ğ˜µğ˜ªğ˜´ğ˜µ ğ˜¢ğ˜¯ğ˜¥ ğ˜‰ğ˜¢ğ˜ºğ˜¦ğ˜´ğ˜ªğ˜¢ğ˜¯ ğ˜´ğ˜µğ˜¢ğ˜µğ˜ªğ˜´ğ˜µğ˜ªğ˜¤ğ˜´, ğ˜£ğ˜¶ğ˜µ ğ˜¢ğ˜­ğ˜´ğ˜° ğ˜¦ğ˜¢ğ˜´ğ˜º ğ˜µğ˜° ğ˜¨ğ˜° ğ˜¸ğ˜³ğ˜°ğ˜¯ğ˜¨ ğ˜ªğ˜§ ğ˜ºğ˜°ğ˜¶ ğ˜¥ğ˜°ğ˜¯'ğ˜µ. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0240e9e0-0a25-4936-9f32-da8688e4874e",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c87079-d298-4371-bb62-1f176b9055a1",
   "metadata": {},
   "source": [
    "::::{sidebar} \n",
    "\n",
    "![](../images/few_good_man.png)\n",
    "\n",
    "::::\n",
    "\n",
    "The title is inspired by a quote from Col. Jessup (interpreted by Jack Nicholson) in _A Few Good Man_ movie.  \n",
    "\n",
    "\n",
    "_\"We follow orders, son.   \n",
    "We follow orders or people die.  \n",
    "It's that simple.\"_ \n",
    "\n",
    "A truly legendary performance!\n",
    "\n",
    "</br>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca131e86-432a-4239-818d-c445a6f55323",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea8c663-bd38-408c-8e63-4272df41f069",
   "metadata": {},
   "source": [
    ":::{admonition} _Disclaimer_\n",
    "\n",
    "Despite the provocative title, and how sometimes the Frequentist approach to these kind of problems is mis-represented in many accounts you find on the web (too many unfortunately of low quality, try to Google it!), <u> _I do not advocate the view that Frequentist is bad and you should always use Bayesian!_ </u>. \n",
    "\n",
    "The usual advice is to **always choose wisely** (obviously!).  \n",
    "My goal is to persuade you that in order to do so <u> **you must understand both well!** </u>(that's the real trick!).\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94cbf8c-def8-4131-8cd8-964bf88afd82",
   "metadata": {},
   "source": [
    ":::{admonition} _Disclaimer 2_\n",
    "\n",
    "For a deep, practical  and very well done discussion on this topic I strongly suggest to have a look at what [Jake VanderPlas has written in his blog](http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/). Here I followed his approach in presenting these kind of problems.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc950d3c-7dcb-4fff-9b7b-814aea144b02",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ba9eb4-17b8-413e-b8d2-7c25ee16808e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Issues With Early Covid-19 Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a23b71-e1c7-41ff-ba10-da8c4d82b382",
   "metadata": {},
   "source": [
    "At the beginning of the pandemic (Feb-Mar 2020) we knew very little about this new disease and, above all, how extended was  spread and how deadly it was. The only available information, repeated tirelessly by the media, were about the number and fraction of people tested positive, how many of them needed hospitalization and, unfortunately, the number of deaths.\n",
    "\n",
    "What added even more rage for people like me that digest data for a living, was the mis-use and mis-interpretation of those numbers and figures. Both by traditional media and, exponentially magnified, by the totally uncontrolled arena of social media. \n",
    "\n",
    "In fact, it was clear to anybody with minimal statistic background that all the extrapolations about the spread, seriousness, death rate, etc..  of the disease (_statistic inference_ in our jargon) from the _daily_ rate of infection announcements (as the number positives over the total tests done) was **completely meaningless** and totally biased. \n",
    "\n",
    "What it was needed - as many pointed out -  was a **controlled testing on a randomly selected sample of people**. Unfortunately at that time it was not possible to do it. The limited supply of testing kits that were prioritized to key workers and people with symptoms. That was totally understandable. \n",
    "\n",
    "But the inability to produce unbiased data was not a justification to use biased data as an alternative!!\n",
    "\n",
    "However <u>**there was an important exception to this lack of unbiased data:**</u> the [Diamond Princess cruise ship](https://en.wikipedia.org/wiki/COVID-19_pandemic_on_cruise_ships) (and others later). \n",
    "\n",
    "Because of the isolated environment and relatively low number, **all** passengers were tested _independently from the fact they reported symptoms or not_. \n",
    "\n",
    "For some time, the data from cruise ships have been the only unbiased ones available. Many scientists used these data for early studies of the Covid-19 (i.e. [\"What the cruise-ship outbreaks reveal about COVID-19\"](https://www.nature.com/articles/d41586-020-00885-w) published in _Nature_ on  26 March 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c4f605-d217-4ecc-a872-196a961f9190",
   "metadata": {},
   "source": [
    "## A Statistical Problem on Conditional Inference\n",
    "\n",
    "Those dramatic events at early stage of the pandemic reminded me examples of **conditional inferences**, an advanced statistical concept. They are fairly well known,  with first examples dating back to the reverend Thomas Bayes in 1763, that  discussed a \"billiard problem\" [in his paper](https://en.wikipedia.org/wiki/An_Essay_towards_solving_a_Problem_in_the_Doctrine_of_Chances). \n",
    "\n",
    "Almost any book on Statistics has a version of these kind of problems, and for a good reason! They really challenge your understanding of statistical inference, and make you appreciate the subtleties behind the Frequentist and Bayesian approach to probability. \n",
    "\n",
    "It is **only after** a full understanding of these subtleties that you can really be in a position to **\"choose wisely**\"!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3970763b-f48c-4ba2-910e-7813d17b6900",
   "metadata": {},
   "source": [
    ":::{topic} A Covid-19 Infected Cruise Ship Problem\n",
    "\n",
    "\n",
    "A cruise ship docked on the port you are responsible for. They have reported people with Covid-19 symptoms. All passengers have being tested, and you have to dispatch ambulances to take people tested positive in dedicated hubs for treatment. \n",
    "\n",
    "You assess the situation as the following:\n",
    "* So far M=35 passengers got their Covid-19 test results, with Q=7 tested positive. \n",
    "* They have been already disembarked and taken care accordingly \n",
    "* There are still N=70 people on board, with the  Covid-19 test results still pending.\n",
    "* You only have K=22 ambulances left.\n",
    "* One ambulance can carry only one positive passenger.\n",
    "\n",
    "At this point you get a call from the crisis center headquarter asking you if you need more ambulances. They explain that ambulances are needed everywhere and this will be your only chance to have more ambulances. However you should only ask what is deemed necessary, many people lives are at stake.\n",
    "\n",
    "Clearly to be 100% safe, you should have 70 ambulances; you will be covered no matter what. \n",
    "\n",
    "But ambulances are scarce, so you decide to take a reasonable risk:  _you will ask for more ambulances only if the probability that 22 ambulances are not enough is higher than 10%_\n",
    "\n",
    "What you should answer then? \n",
    "\n",
    "**Will the number of positive tests on the remaining 70 passengers be greater than 22 with a probability higher than 10% ?**\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4cdb18-aeb6-4e47-b5bf-61ab19468732",
   "metadata": {},
   "source": [
    "## Some possible answers\n",
    "\n",
    "There are many ways to reason about this problem, I will discuss four of them:\n",
    ":Frequentist Approach: This is how a Frequentist _might_ answer\n",
    ":Bayesian Approach: This is how a  Bayesian _will_ probbably answer\n",
    ":Professional Approach: This is how a Professional statistician  _may_ answer\n",
    ":Caveman Approach: This is how a person knowing nothing or enough about conditional probability, maximum likelihood, nuisance parameters, Beta-Binomial distribution, etc.. , but with very good coding skills, _might_ answer. A DevOps or MLOps engineer for example.\n",
    "\n",
    "In the following  we assume the first 35 people were randomly selected, _i.e._ their rate of infection is the same as the remaining 70 passengers (_never ever ever_ give priority to woman, children or elderly as a statistician,it will totally bias your sample!!).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e771416-acab-4883-a784-21951d30c223",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "### How a Frequentistic _might_ answer\n",
    "\n",
    "A frequentistic approach could go like this:\n",
    "\n",
    "* The actual (true) infection rate is $\\rho$. We don't know it, but we can infer our best guess by the measurements we have.\n",
    "* For any given passenger already tested, we can calculate the probability (binomial) distribution of the observation (positive or not), given $\\rho$.\n",
    "* As we have $M=35$ observations, we  can calculate the _likelihood_ $\\mathcal{L}(\\rho)$ of observing $Q=7$ positives as join probability of $M$ independent observations\n",
    "* Finally we calculate which value of $\\rho$ maximize the _likelihood_ $\\mathcal{L}(\\rho)$  of observing the measurements we observe. That result $\\hat{\\rho}$ is our best guess for $\\rho$.\n",
    "\n",
    "After all those steps and calculations we find that our best guess $\\hat{\\rho}$ is (surprise!):\n",
    "\n",
    "$$ \\hat{\\rho} = \\frac{Q}{M} = \\frac{7}{35} $$\n",
    "\n",
    "Since the infection rate is the same for all passengers, the probability of $K$ positive cases out of the remaining $N$ passengers is easy to calculate (binomial probability):\n",
    "\n",
    "$$ P(K|N,M,Q) = \\hat{\\rho}^K (1-\\hat{\\rho})^{N-K}  = \\bigg(\\frac{Q}{M}\\bigg)^K \\bigg(1-\\frac{Q}{M}\\bigg)^{N-K} = \\frac{Q^K}{M^N}(M-Q)^{N-K}  $$ \n",
    "\n",
    "In particular we want to know the overall probability $\\mathcal{P}(K_{max})$ that the number of positive cases is above $K_{max} = 22$:\n",
    "\n",
    "$$\\mathcal{P}(K_{max}) = \\sum_{K > K_{max}} P_{K}  $$\n",
    "\n",
    "\n",
    "If  $\\mathcal{P}(K_{max})$ is above 10% the risk is too high, and we need more ambulances.\n",
    "\n",
    "Using Python this is an easy task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be6c90f9-e32e-4355-9620-6bb187119aa4",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from scipy.special import factorial as f_\n",
    "from scipy.special import comb\n",
    "from scipy.stats import binom\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "## P(K|N,M,Q)\n",
    "def FreqProbability(k,n,m,q):\n",
    "    \n",
    "    p_hat = q/m\n",
    "    prob = binom.pmf(k,n,p_hat)\n",
    "    return prob\n",
    "\n",
    "## P(K_max)\n",
    "def ProbabilitySum(func, k_max ,n,m,q):\n",
    "    prob_v = np.array([func(i,n,m,q) for i in range(k_max+1,n+1)])\n",
    "    #print(prob_v)\n",
    "    return prob_v.sum()\n",
    "\n",
    "k_max = 22\n",
    "N = 70\n",
    "M = 35\n",
    "Q = 7\n",
    "\n",
    "p_max = ProbabilitySum(FreqProbability, k_max, N, M, Q)\n",
    "\n",
    "print(f'Total probability for K_max={k_max}: {p_max:.6f} ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f956c7-98cd-455f-b2ef-65d6f85f630f",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "In other words, this frequentistic-based approach tells us that there is only 0.8% probability that 22 ambulances we have are insufficient.\n",
    "\n",
    ":Answer: We don't need more ambulances\n",
    "\n",
    "### How a Bayesian  _does_ answer\n",
    "\n",
    "A bayesian will treat this problem as a simple case of **conditional probability with a nuisance parameter to _marginalize_**\n",
    "\n",
    "Let's define for clarity:  \n",
    ":A: there are $K$ positive  cases among the $N=70$ passenger on board   \n",
    ":D: the data we have, _i.e._ there are $Q=7$ positive cases among the $M=35$ passengers already tested  \n",
    ":$\\rho$: the unknown infection rate   \n",
    "\n",
    "What we want is $P(A,\\rho|D)$, and since $\\rho$ is unknown, it is marginalized:\n",
    "$$\n",
    "P(A|D) = \\int{P(A,\\rho|D)d\\rho}\n",
    "$$\n",
    "\n",
    "The trick now is to manipulate this expression until we get something we know how to calculate. Using the law of conditional probability ($P(A\\cap B) = P(A|B) \\cdot P(B)$) and the Bayes' theorem we have:\n",
    "\n",
    "$$\n",
    "P(A,\\rho|D) = P(A|\\rho, D)\\cdot P(\\rho|D) \\\\\n",
    "P(\\rho|D) = \\frac{P(D|\\rho) \\cdot P(\\rho)}{p(D)}\\\\\n",
    "P(D) = \\int{P(D|\\rho) \\cdot P(\\rho)\\ d\\rho}\n",
    "$$\n",
    "\n",
    "Using the binomial probability, we also have:\n",
    "\n",
    "$$\n",
    "P(A|\\rho, D)  =  {K \\choose N} {\\rho}^K (1-{\\rho})^{N-K} \\\\\n",
    "P(D|\\rho) = {Q \\choose M} {\\rho}^Q (1-{\\rho})^{M-Q}\n",
    "$$\n",
    "\n",
    "The last bit is what to put for $P(\\rho)$, the _prior_ on the probability distribution of $\\rho$. What we can say is that it can be equally anything  between 0 and 1 (flat distribution, $P(\\rho)=c$). Put everything together:\n",
    "\n",
    "$$\n",
    "   \\begin{align}\n",
    "      P(A|D) & = \\int{P(A,\\rho|D)d\\rho} = \\int{P(A|\\rho, D)   \\cdot P(\\rho|D)  \\   d\\rho}   \\\\\n",
    "             & = \\int{P(A|\\rho, D)   \\cdot \\frac{P(D|\\rho) \\cdot P(\\rho)}{p(D)}  \\   d\\rho} \\\\\n",
    "             & = \\frac{\\int{P(A|\\rho, D)   \\cdot P(D|\\rho) \\cdot P(\\rho)  \\   d\\rho}}{\\int{P(D|\\rho) \\cdot P(\\rho)  \\   d\\rho}} \\\\\n",
    "             & =  {K \\choose N} \\frac{\\int_0^1{\\rho^K (1-\\rho)^{N-K} \\cdot \\rho^Q (1-\\rho)^{M-Q} d\\rho}}{\\int_0^1{{\\rho}^Q (1-{\\rho})^{M-Q} \\   d\\rho}}\n",
    "   \\end{align}\n",
    "$$\n",
    "\n",
    "After calculating these simple integrals, we get the conditional probability to observe $K$ positives on the remaining passengers:\n",
    "\n",
    "$$\n",
    "P(A|D) = P(K|N,M,Q) = {K \\choose N} \\frac{(K+Q)!}{Q!} \\cdot\n",
    "\\frac{(N-K+(M-Q))! }{(N+M+1)} \\cdot\n",
    "\\frac{(M+1)!}{(M-Q)!}\n",
    "$$\n",
    "\n",
    "As in the frequentistic case, we can get the overall probability $\\mathcal{P}(K_{max})$ that the number of positive cases is above $K_{max} = 22$ from :\n",
    "\n",
    "$$\\mathcal{P}(K_{max}) = \\sum_{K = K_{max}+1}^N P(K|N,M,Q)  $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fa8dd4-fef0-4752-82b8-c11236c0c9f2",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "Calculating it with python is straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e219238-81b3-40f6-9583-9efe930f50ae",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total probability for K_max=22: 0.109212 \n"
     ]
    }
   ],
   "source": [
    "## integral value\n",
    "def ProbIntegralValue(a,b):\n",
    "    return f_(a)*f_(b)/f_(a+b+1)\n",
    "\n",
    "\n",
    "def BayesianProbability(k,n,m,q):\n",
    "    \n",
    "    a = q\n",
    "    b = m-a\n",
    "    den = ProbIntegralValue(a,b)\n",
    "    \n",
    "    a = k+q\n",
    "    b = n+m-a\n",
    "    num = comb(n,k)*ProbIntegralValue(a,b)\n",
    "    \n",
    "    return num/den\n",
    "\n",
    "k_max = 22\n",
    "N = 70\n",
    "M = 35\n",
    "Q = 7\n",
    "\n",
    "p_max = ProbabilitySum(BayesianProbability, k_max, N, M, Q)\n",
    "\n",
    "print(f'Total probability for K_max={k_max}: {p_max:.6f} ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0978eaa6-1586-41cf-bbdd-61dafa49a8f1",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "With this bayesian approach, the probability we need more than 22 ambulances is 11%. That's too high of a risk.\n",
    "\n",
    ":Answer: We do need more ambulances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e139ea0-78a6-4364-912e-e15f436b2f34",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "### How a cave man would answer\n",
    "\n",
    "In this contest a cave man is someone that doesn't know anything or enough about statistical inference, conditional probability, maximum likelihood, marginalization, nuisance parameters, Bayes' theorem, etc.. But he's very good with Python! \n",
    "\n",
    "Hence his approach is to write a simple **toy Monte Carlo simulation**:\n",
    "* Assuming a random infection rate, create a random, _fake_ scenario of infected passengers in agreement with the given observations, \n",
    "* Just annotate if that scenario has a positive outcome, i.e. the number of positives are less than 22\n",
    "* Repeat zillion of times the procedure\n",
    "\n",
    "In the end, just counting the fraction of the generated scenarios with positive outcome will give the probability required \n",
    "\n",
    "Using Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a61d018-7a09-4458-a9c0-4d1da0f3a5ec",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... experiment done\n",
      "... experiment done\n",
      "... experiment done\n",
      "... experiment done\n",
      "... experiment done\n",
      "... experiment done\n",
      "... experiment done\n",
      "... experiment done\n",
      "... experiment done\n",
      "... experiment done\n",
      "Probability of 22 positive in next 70 tosses after observing 7 positives in 35 tosses: (10.92662 +- 0.14411) %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def MakeExperiment(N, p):\n",
    "    ## make a random scenario of N tosses with probability p\n",
    "    rnd = np.random.rand(N)\n",
    "    return (rnd<p).astype(int) ## 1 with probability p, 0 with probability (1-p)\n",
    "    \n",
    "def CheckExperiment(experiment, observed_tosses, positive_observed, check_type = 'measurement'):\n",
    "    ## check if a given experiment satisfy requirements:\n",
    "    ## check_type = 'measurement'\n",
    "    ##          Requirement: having 'positive_observed' in the first 'observed_tosses' tosses\n",
    "    ## check_type = 'expectation'\n",
    "    ##          Requirement: having 'positive_observed' in the tosses after the first 'observed_tosses'\n",
    "    #print(experiment, observed_tosses, positive_observed, check_type)\n",
    "    assert(len(experiment)> observed_tosses)\n",
    "    assert(observed_tosses >= positive_observed)\n",
    "\n",
    "    test_passed = False\n",
    "    \n",
    "    ## positives in observed\n",
    "    if (check_type == 'measurement'):\n",
    "        positives = experiment[:observed_tosses].sum()\n",
    "        if positives == positive_observed: test_passed = True\n",
    "    \n",
    "    ## positive in not-observed\n",
    "    if (check_type == 'expectation'):\n",
    "        positives = experiment[observed_tosses:].sum()\n",
    "        if positives > positive_observed: test_passed = True\n",
    "        \n",
    "    if test_passed:\n",
    "         return experiment\n",
    "    \n",
    "    return []\n",
    "\n",
    "def RunSimulation(Tot_number_experiments, N, m, k, q):\n",
    "    N_experiment_accepted = 0\n",
    "    N_experiment_sucessed = 0\n",
    "    for i in range(Tot_number_experiments):\n",
    "        \n",
    "        p = random.random() ## random p    \n",
    "        experiment = CheckExperiment(MakeExperiment(N+m,p), m, q) # Make experiment compatible with observation\n",
    "        if len(experiment) == 0: continue # if not passing the check, move on\n",
    "        N_experiment_accepted += 1\n",
    "        good_experiment = CheckExperiment(experiment, m, k, check_type = 'expectation') ## Now check if compatible with expectations\n",
    "        if len(good_experiment): N_experiment_sucessed += 1\n",
    "    \n",
    "    print(\"... experiment done\")\n",
    "    return np.array([N_experiment_accepted, N_experiment_sucessed])\n",
    "    \n",
    "\n",
    "\n",
    "## Observed \n",
    "observed_tosses = 35 \n",
    "positive_in_observed = 7\n",
    "## To predict\n",
    "future_tosses = 70\n",
    "positive_in_future = 22\n",
    "## Number of simulated experiments\n",
    "Tot_number_experiments = 10000000\n",
    "\n",
    "###-----\n",
    "n_bunches = 10 ## split in bunches to estimate the error\n",
    "N_in_bunch = int(Tot_number_experiments/n_bunches)\n",
    "\n",
    "result = np.array([RunSimulation(N_in_bunch, future_tosses, observed_tosses, positive_in_future, positive_in_observed) for i in range(n_bunches)])\n",
    "\n",
    "## With error estimate\n",
    "prob = result[:,1]/result[:,0]\n",
    "print(\"Probability of {} positive in next {} tosses after observing {} positives in {} tosses: ({:.5f} +- {:.5f}) %\".format( \\\n",
    "    positive_in_future, future_tosses, positive_in_observed, observed_tosses, prob.mean()*100, prob.std()*100 ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5f9432-1655-4e4b-ac00-74681858dfc6",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "### How a Professional could answer\n",
    "\n",
    "The probability of $a$ positives in $A$ passengers randomly selected from all the $B$ passengers ($B \\ge  A$) among which there are exactly $b$ positives follows the  **Hypergeometric distribution**, i.e.:\n",
    "\n",
    "$$\n",
    "p(a|b,B,A) =  \\mathcal{HG}(a|b,B,A)\n",
    "$$\n",
    "\n",
    "In this problem however we know $a$ and we want the probability distribution for $b$, i.e. $p(b|a,B,A)$. Since the _conjugate prior_ of a Hypergeometric distribution is a **Beta-Binomial distribution**, the posterior distribution  $p(b|a,B,A)$ is still a Beta-Binomial distribution. \n",
    "\n",
    "In particular the conjugate prior is $\\mathcal{BB}(b,B,\\alpha,\\beta)$ and the corresponding posterior is:\n",
    "\n",
    "$$\n",
    "p(b|a,B,A) = \\mathcal{BB}(b-a, B-A,\\alpha+a,\\beta+(A-a))\n",
    "$$\n",
    "\n",
    "Using the notation of the problem ($A=M, a=Q, B=N+M, b=K+Q$) and choosing a uniform prior ($\\alpha = \\beta = 1$):\n",
    "\n",
    "$$\n",
    "P(K|N,M,Q) = \\mathcal{BB}(K, N, Q+1, M-Q+1)\n",
    "$$\n",
    "\n",
    "\n",
    "We can get the overall probability $\\mathcal{P}(K_{max})$ that the number of positive cases is above $K_{max} = 22$ from :\n",
    "\n",
    "$$\\mathcal{P}(K_{max}) = \\sum_{K = K_{max}+1}^N P(K|N,M,Q)  $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dcfb741-c77f-43ab-8c94-deee09735646",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total probability for K_max=22: 0.109212 \n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import betabinom\n",
    "\n",
    "##- Input\n",
    "m=35\n",
    "q=7\n",
    "n=70\n",
    "k=22\n",
    "\n",
    "## Use the sf = 1-cdf to have the overall probability\n",
    "p = betabinom.sf(k,n,q+1,m-q+1)\n",
    "\n",
    "print(f'Total probability for K_max={k}: {p:.6f} ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ce0be9-c5d6-4aeb-9869-a35c74a1fef8",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    "\n",
    ":::{tab-item} Frequentist\n",
    ":sync: key1\n",
    "\n",
    "A frequentistic approach could go like this:\n",
    "\n",
    "* The actual (true) infection rate is $\\rho$. We don't know it, but we can infer our best guess by the measurements we have.\n",
    "* For any given passenger already tested, we can calculate the probability (binomial) distribution of the observation (positive or not), given $\\rho$.\n",
    "* As we have $M=35$ observations, we  can calculate the _likelihood_ $\\mathcal{L}(\\rho)$ of observing $Q=7$ positives as join probability of $M$ independent observations\n",
    "* Finally we calculate which value of $\\rho$ maximize the _likelihood_ $\\mathcal{L}(\\rho)$  of observing the measurements we observe. That result $\\hat{\\rho}$ is our best guess for $\\rho$.\n",
    "\n",
    "After all those steps and calculations we find that our best guess $\\hat{\\rho}$ is (surprise!):\n",
    "\n",
    "$$ \\hat{\\rho} = \\frac{Q}{M} = \\frac{7}{35} $$\n",
    "\n",
    "Since the infection rate is the same for all passengers, the probability of $K$ positive cases out of the remaining $N$ passengers is easy to calculate (binomial probability):\n",
    "\n",
    "$$ P(K|N,M,Q) = \\hat{\\rho}^K (1-\\hat{\\rho})^{N-K}  = \\bigg(\\frac{Q}{M}\\bigg)^K \\bigg(1-\\frac{Q}{M}\\bigg)^{N-K} = \\frac{Q^K}{M^N}(M-Q)^{N-K}  $$ \n",
    "\n",
    "In particular we want to know the overall probability $\\mathcal{P}(K_{max})$ that the number of positive cases is above $K_{max} = 22$:\n",
    "\n",
    "$$\\mathcal{P}(K_{max}) = \\sum_{K > K_{max}} P_{K}  $$\n",
    "\n",
    "\n",
    "If  $\\mathcal{P}(K_{max})$ is above 10% the risk is too high, and we need more ambulances.\n",
    "\n",
    ":::\n",
    "\n",
    ":::{tab-item} Bayesian\n",
    ":sync: key2\n",
    "\n",
    "A bayesian will treat this problem as a simple case of **conditional probability with a nuisance parameter to _marginalize_**\n",
    "\n",
    "Let's define for clarity:  \n",
    ":A: there are $K$ positive  cases among the $N=70$ passenger on board   \n",
    ":D: the data we have, _i.e._ there are $Q=7$ positive cases among the $M=35$ passengers already tested  \n",
    ":$\\rho$: the unknown infection rate   \n",
    "\n",
    "What we want is $P(A,\\rho|D)$, and since $\\rho$ is unknown, it is marginalized:\n",
    "\n",
    "$$\n",
    "P(A|D) = \\int{P(A,\\rho|D)d\\rho}\n",
    "$$\n",
    "\n",
    "The trick now is to manipulate this expression until we get something we know how to calculate. Using the law of conditional probability ($P(A\\cap B) = P(A|B) \\cdot P(B)$) and the Bayes' theorem we have:\n",
    "\n",
    "$$\n",
    "P(A,\\rho|D) = P(A|\\rho, D)\\cdot P(\\rho|D) \\\\\n",
    "P(\\rho|D) = \\frac{P(D|\\rho) \\cdot P(\\rho)}{p(D)}\\\\\n",
    "P(D) = \\int{P(D|\\rho) \\cdot P(\\rho)\\ d\\rho}\n",
    "$$\n",
    "\n",
    "Using the binomial probability, we also have:\n",
    "\n",
    "$$\n",
    "P(A|\\rho, D)  =  {K \\choose N} {\\rho}^K (1-{\\rho})^{N-K} \\\\\n",
    "P(D|\\rho) = {Q \\choose M} {\\rho}^Q (1-{\\rho})^{M-Q}\n",
    "$$\n",
    "\n",
    "The last bit is what to put for $P(\\rho)$, the _prior_ on the probability distribution of $\\rho$. What we can say is that it can be equally anything  between 0 and 1 (flat distribution, $P(\\rho)=c$). Put everything together:\n",
    "\n",
    "$$\n",
    "   \\begin{align}\n",
    "      P(A|D) & = \\int{P(A,\\rho|D)d\\rho} = \\int{P(A|\\rho, D)   \\cdot P(\\rho|D)  \\   d\\rho}   \\\\\n",
    "             & = \\int{P(A|\\rho, D)   \\cdot \\frac{P(D|\\rho) \\cdot P(\\rho)}{p(D)}  \\   d\\rho} \\\\\n",
    "             & = \\frac{\\int{P(A|\\rho, D)   \\cdot P(D|\\rho) \\cdot P(\\rho)  \\   d\\rho}}{\\int{P(D|\\rho) \\cdot P(\\rho)  \\   d\\rho}} \\\\\n",
    "             & =  {K \\choose N} \\frac{\\int_0^1{\\rho^K (1-\\rho)^{N-K} \\cdot \\rho^Q (1-\\rho)^{M-Q} d\\rho}}{\\int_0^1{{\\rho}^Q (1-{\\rho})^{M-Q} \\   d\\rho}}\n",
    "   \\end{align}\n",
    "$$\n",
    "\n",
    "After calculating these simple integrals, we get the conditional probability to observe $K$ positives on the remaining passengers:\n",
    "\n",
    "$$\n",
    "P(A|D) = P(K|N,M,Q) = {K \\choose N} \\frac{(K+Q)!}{Q!} \\cdot\n",
    "\\frac{(N-K+(M-Q))! }{(N+M+1)} \\cdot\n",
    "\\frac{(M+1)!}{(M-Q)!}\n",
    "$$\n",
    "\n",
    "We can get the overall probability $\\mathcal{P}(K_{max})$ that the number of positive cases is above $K_{max} = 22$ from :\n",
    "\n",
    "$$\\mathcal{P}(K_{max}) = \\sum_{K = K_{max}+1}^N P(K|N,M,Q)  $$\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    ":::{tab-item} Professional\n",
    ":sync: key4\n",
    "\n",
    "\n",
    "A Professional would recognize that he probability of $a$ positives in $A$ passengers randomly selected from all the $B$ passengers among which there are exactly $b$ positives follows a  **Hypergeometric distribution**, i.e.:\n",
    "\n",
    "$$\n",
    "p(a|b,B,A) =  \\mathcal{HG}(a|b,B,A)\n",
    "$$\n",
    "\n",
    "In this problem however we know $a$ and with this information we want, on the still-to-be-tested passengers ($B-A$), the distribution of the number of positives still unknown ($b-a$)\n",
    "\n",
    "It is convenient to choose for $b$ a **Beta-Binomial distribution** as _prior_, as it is a _conjugate prior_ of a Hypergeometric distribution:\n",
    "\n",
    "$$\n",
    "b \\approx \\mathcal{BB}(b|B,\\alpha,\\beta)\n",
    "$$\n",
    "\n",
    "This implies that the unknown number of positives $b-a$ is also a Beta-Binomial distribution (_posterior_):\n",
    "\n",
    "$$\n",
    "b-a \\approx \\mathcal{BB}(b-a|B-A,\\alpha+a,\\beta+(A-a))\n",
    "$$\n",
    "\n",
    "where the hyperparameters $\\alpha,\\beta$ of the prior are added to the observed numbers of positives and negatives passengers $a, A-a$.\n",
    "\n",
    "Using the notation of the problem ($A=M, a=Q, B=N+M, b=K+Q$) and choosing a uniform prior ($\\alpha = \\beta = 1$):\n",
    "\n",
    "$$\n",
    "P(K|N,M,Q) = \\mathcal{BB}(K, N, Q+1, M-Q+1)\n",
    "$$\n",
    "\n",
    "\n",
    "We can get the overall probability $\\mathcal{P}(K_{max})$ that the number of positive cases is above $K_{max} = 22$ from :\n",
    "\n",
    "$$\\mathcal{P}(K_{max}) = \\sum_{K = K_{max}+1}^N P(K|N,M,Q)  $$\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    ":::{tab-item} Caveman\n",
    ":sync: key3\n",
    "\n",
    "A caveman would just write a simple **toy Monte Carlo simulation**, for example as follow:\n",
    "* Assume a random infection rate, \n",
    "* Create a random, _fake_ scenario of infected passengers in agreement with the given observations, \n",
    "* Simply annotate (yes or no) if that scenario has an \"unwanted\" outcome, i.e. the number of tested positives passengers are more than 22\n",
    "* Generate zillion of scenarios\n",
    "\n",
    "In the end, the fraction of the generated scenarios with an \"unwanted\" outcome will give the probability required. No statistic knowledge needed, just a ratio of two integers. \n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aa8d97-a385-4d20-9231-17509bef31eb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    ":::::{dropdown} Python Code\n",
    ":animate: fade-in-slide-down\n",
    ":color: success\n",
    ":icon: code\n",
    ":margin: auto\n",
    "\n",
    "\n",
    "\n",
    "::::{tab-set}\n",
    "\n",
    ":::{tab-item} Frequentist \n",
    ":sync: key1\n",
    "\n",
    "```python\n",
    "from scipy.special import factorial as f_\n",
    "from scipy.special import comb\n",
    "from scipy.stats import binom\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "## P(K|N,M,Q)\n",
    "def FreqProbability(k,n,m,q):\n",
    "    \n",
    "    p_hat = q/m\n",
    "    prob = binom.pmf(k,n,p_hat)\n",
    "    return prob\n",
    "\n",
    "## P(K_max)\n",
    "def ProbabilitySum(func, k_max ,n,m,q):\n",
    "    prob_v = np.array([func(i,n,m,q) for i in range(k_max+1,n+1)])\n",
    "    #print(prob_v)\n",
    "    return prob_v.sum()\n",
    "\n",
    "k_max = 22\n",
    "N = 70\n",
    "M = 35\n",
    "Q = 7\n",
    "\n",
    "p_max = ProbabilitySum(FreqProbability, k_max, N, M, Q)\n",
    "\n",
    "print(f'Total probability for K_max={k_max}: {p_max:.6f} ')\n",
    "```\n",
    "\n",
    "\n",
    ":::\n",
    "\n",
    ":::{tab-item} Bayesian \n",
    ":sync: key2\n",
    "\n",
    "```python\n",
    "from scipy.special import factorial as f_\n",
    "from scipy.special import comb\n",
    "from scipy.stats import binom\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "## integral value\n",
    "def ProbIntegralValue(a,b):\n",
    "    return f_(a)*f_(b)/f_(a+b+1)\n",
    "\n",
    "\n",
    "def BayesianProbability(k,n,m,q):\n",
    "    \n",
    "    a = q\n",
    "    b = m-a\n",
    "    den = ProbIntegralValue(a,b)\n",
    "    \n",
    "    a = k+q\n",
    "    b = n+m-a\n",
    "    num = comb(n,k)*ProbIntegralValue(a,b)\n",
    "    \n",
    "    return num/den\n",
    "\n",
    "## P(K_max)\n",
    "def ProbabilitySum(func, k_max ,n,m,q):\n",
    "    prob_v = np.array([func(i,n,m,q) for i in range(k_max+1,n+1)])\n",
    "    #print(prob_v)\n",
    "    return prob_v.sum()\n",
    "\n",
    "\n",
    "k_max = 22\n",
    "N = 70\n",
    "M = 35\n",
    "Q = 7\n",
    "\n",
    "p_max = ProbabilitySum(BayesianProbability, k_max, N, M, Q)\n",
    "\n",
    "print(f'Total probability for K_max={k_max}: {p_max:.6f} ')\n",
    "\n",
    "```\n",
    ":::\n",
    "\n",
    "\n",
    ":::{tab-item} Professional \n",
    ":sync: key4\n",
    "\n",
    "```python\n",
    "from scipy.stats import betabinom\n",
    "\n",
    "##- Input\n",
    "m=35\n",
    "q=7\n",
    "n=70\n",
    "k=22\n",
    "\n",
    "## Use the sf = 1-cdf to have the overall probability\n",
    "p = betabinom.sf(k,n,q+1,m-q+1)\n",
    "\n",
    "print(f'Total probability for K_max={k}: {p:.6f} ')\n",
    "\n",
    "```\n",
    ":::\n",
    "\n",
    "\n",
    ":::{tab-item} Caveman \n",
    ":sync: key3\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def MakeExperiment(N, p):\n",
    "    ## make a random scenario of N tosses with probability p\n",
    "    rnd = np.random.rand(N)\n",
    "    return (rnd<p).astype(int) ## 1 with probability p, 0 with probability (1-p)\n",
    "    \n",
    "def CheckExperiment(experiment, observed_tosses, positive_observed, check_type = 'measurement'):\n",
    "    ## check if a given experiment satisfy requirements:\n",
    "    ## check_type = 'measurement'\n",
    "    ##          Requirement: having 'positive_observed' in the first 'observed_tosses' tosses\n",
    "    ## check_type = 'expectation'\n",
    "    ##          Requirement: having 'positive_observed' in the tosses after the first 'observed_tosses'\n",
    "    #print(experiment, observed_tosses, positive_observed, check_type)\n",
    "    assert(len(experiment)> observed_tosses)\n",
    "    assert(observed_tosses >= positive_observed)\n",
    "\n",
    "    test_passed = False\n",
    "    \n",
    "    ## positives in observed\n",
    "    if (check_type == 'measurement'):\n",
    "        positives = experiment[:observed_tosses].sum()\n",
    "        if positives == positive_observed: test_passed = True\n",
    "    \n",
    "    ## positive in not-observed\n",
    "    if (check_type == 'expectation'):\n",
    "        positives = experiment[observed_tosses:].sum()\n",
    "        if positives > positive_observed: test_passed = True\n",
    "        \n",
    "    if test_passed:\n",
    "         return experiment\n",
    "    \n",
    "    return []\n",
    "\n",
    "def RunSimulation(Tot_number_experiments, N, m, k, q):\n",
    "    N_experiment_accepted = 0\n",
    "    N_experiment_sucessed = 0\n",
    "    for i in range(Tot_number_experiments):\n",
    "        \n",
    "        p = random.random() ## random p    \n",
    "        experiment = CheckExperiment(MakeExperiment(N+m,p), m, q) # Make experiment compatible with observation\n",
    "        if len(experiment) == 0: continue # if not passing the check, move on\n",
    "        N_experiment_accepted += 1\n",
    "        good_experiment = CheckExperiment(experiment, m, k, check_type = 'expectation') ## Now check if compatible with expectations\n",
    "        if len(good_experiment): N_experiment_sucessed += 1\n",
    "    \n",
    "    print(\"... experiment done\")\n",
    "    return np.array([N_experiment_accepted, N_experiment_sucessed])\n",
    "    \n",
    "\n",
    "\n",
    "## Observed \n",
    "observed_tosses = 35 \n",
    "positive_in_observed = 7\n",
    "## To predict\n",
    "future_tosses = 70\n",
    "positive_in_future = 22\n",
    "## Number of simulated experiments\n",
    "Tot_number_experiments = 10000000\n",
    "\n",
    "###-----\n",
    "n_bunches = 10 ## split in bunches to estimate the error\n",
    "N_in_bunch = int(Tot_number_experiments/n_bunches)\n",
    "\n",
    "result = np.array([RunSimulation(N_in_bunch, future_tosses, observed_tosses, positive_in_future, positive_in_observed) for i in range(n_bunches)])\n",
    "\n",
    "## With error estimate\n",
    "prob = result[:,1]/result[:,0]\n",
    "print(\"Probability of {} positive in next {} tosses after observing {} positives in {} tosses: ({:.5f} +- {:.5f}) %\".format( \\\n",
    "    positive_in_future, future_tosses, positive_in_observed, observed_tosses, prob.mean()*100, prob.std()*100 ))\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    "::::\n",
    ":::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebe253b-335e-4ad4-bdb7-aa6a6f8c63f4",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Running the Python code we can report the final answers\n",
    "\n",
    "\n",
    "**Will the number of positive tests on the remaining 70 passengers be higher than 22 with 10% (or more) probability?**\n",
    "\n",
    ":Frequentist: **NO**. The probability is only 0.8%\n",
    ":Bayesian: **YES**. The probability is 10.92%\n",
    ":Professional: **YES**. The probability is 10.92%\n",
    ":Caveman: **YES**. The probability is (10.92 $\\pm$ 0.14) % \n",
    "\n",
    "The Caveman result accounts for the statistical error on the number of toy Montecarlo generated while the other three approaches are analytical results.\n",
    "\n",
    "But these are just details. \n",
    "\n",
    "The main point is that the Frequentist approach gives the **wrong** answer, and as a consequence people die! (well, to be precise there is a 10.92% probability that nobody dies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e7205b-a0d1-492b-9000-2ffd77b58474",
   "metadata": {},
   "source": [
    "## Discussion and Take Away Message\n",
    "\n",
    "OK, what's going on here?? Were not all those endless frequentistic vs. bayesian debates basically all but philosophical banters? Some pedantic interpretations of the concept of probability but basically giving identical answers in all practical cases? And this is why it is important not only to know them, but also to understand them well. \n",
    "\n",
    ":::{important}\n",
    "Frequentistic and Bayesian **never give the same answers** (maybe the same results), for the simple fact that **they don't answer the same question**!\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14ab41b-5ca5-460d-8b50-7da4348abe54",
   "metadata": {},
   "source": [
    "### Is the frequentistic statistical inference all wrong?\n",
    "\n",
    "Is this a counterexample that the frequentist approach is wrong? Obviously not! \n",
    "\n",
    "Any person with a good statistic background already realized from the start that the frequentist approach I showed above is not what a frequentist would do. \n",
    "\n",
    "To explain well why is beyond the scope of this post (this is also the reason for the immense literature on these topics!). But I will put here few points that are important to have crystal clear for a proper application of statistic inference, whatever approach one might use:\n",
    "\n",
    "* A Frequentist would already have argued about the question asked. The objection is on the meaning of _\"90% probability that at most 22 passengers on board will test positive\"_. For a frequentist there is not such a probability. Either it will happen or it will not. That's the truth. We don't know what it will be, but there is not 11% or 0.8% or whatever probability. It is yes or it is no.\n",
    "\n",
    "\n",
    "* In any case, a Frequentist  would probably have framed the problem in term of hypothesis testing, and/or confident interval. But this **IS NOT** the same as the  Bayesian counterparts (often called _credible region_). They are **NOT** answering the same question!\n",
    "\n",
    "* The freqentist inference gives procedures on statistics problems. They account of observations in the calculation of the confidence interval, but the statistic interpretation is on the _procedure_. The _procedure_ does come with a frequency guarantee that the truth number of positives is within the frequentist confidence interval 95% of the time (or whatever threshold is used), not the particular confidence interval.  \n",
    "\n",
    "* If the frequentist procedure is applied to 100 cruise ships in the same situation, for 95 ships the calculated confident interval contains the true value of positive passengers. If you consider only 1 ship though , it may be one of those 95 or one of the remaining 5. In the latter case the calculated confidence interval **DOES NOT** contain the true value. As for the frequentist spirit, the truth is or is not in the calculated interval, there is no probability.\n",
    "\n",
    "* In this sense _conditional_ inference is  not Frequentist. Confidence Intervals are _un_-conditional.\n",
    "\n",
    "As a final note, it seems in this particular case the Bayesian approach is a better (in the sense of \"more intuitive\") choice. But I still remember a warning I once found somewhere while reading about these topics:\n",
    "\n",
    "```{epigraph}\n",
    "To those who attach themselves to either camp: remember, there is plenty of ammunitions in term of counterexamples on **BOTH** sides!\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26f26b8-eed7-41c8-8b83-1cd32dfa6ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "author": "Andrea Bocci",
  "category": "statistics",
  "date": "2022-11-26",
  "excerpt": 0,
  "image": 0,
  "interactive": true,
  "kernelspec": {
   "display_name": "Python [conda env:ds-base]",
   "language": "python",
   "name": "conda-env-ds-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "tags": [
   "notebook",
   "bayesian"
  ],
  "title": "Follow A Bayesian, Or People Die!",
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
